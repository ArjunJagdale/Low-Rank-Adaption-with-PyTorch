{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JLkOzrbZMHkZ"
   },
   "source": [
    "# Install & Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1Z-5E9EYJFmw"
   },
   "outputs": [],
   "source": [
    "# âœ… Run this cell in Colab to install necessary packages\n",
    "!pip install transformers datasets scikit-learn --quiet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "liW-ETiEJF-R",
    "outputId": "fb270ac0-b97f-48d3-87e9-cb9a13eda773"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from datasets import load_dataset\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import numpy as np\n",
    "import random\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "# âœ… Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RUKqZ1-gMNMr"
   },
   "source": [
    "# Load SST-2 Dataset (via Hugging Face datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 589,
     "referenced_widgets": [
      "0e8583863f2843888fccac84beaa6bbf",
      "3c4c804b673446e8bb652507a64500d1",
      "512ae9496fe34f509d83780e27ef053e",
      "a096380f3f284a07874c4144810f157b",
      "79e31e33e6c844839fcb6371feb8bf11",
      "89b1a9af9515443d8b7501fe45ac0c3e",
      "01328642d4464144888500512d087541",
      "2a4e6d18859c4aadaa9f13ef1ed76914",
      "3f8817c53f0d4bdebbaf87d85a571dbd",
      "cd94a1b4f32e48acb653fb9e546419a4",
      "84512f92f9734f4b84cb2692210563b2",
      "82bc6fe3109146879c43aeb0a8227f26",
      "d82c71ea51a3470b84abe949d302de32",
      "5b8c2a169359498189dbfdcc13b1cd4b",
      "207cb35a186f4ce089ddb91c2a9a4671",
      "8489ef15583f48d0bd83279bc01a6edc",
      "670a934a7537482daf7190f6175b96cf",
      "d5e6375ba5e24121ab5badf57bcfeb98",
      "f64e170316464718b23f9b88b862f752",
      "76444f5733714402b232641bbd9e7f98",
      "f84a4d7916ad4364ad7a6985278fbfa2",
      "9f0e9fb99d784f128b676e04bdfe5cab",
      "4004c1b3b82249bd8bd36d4f00bc40cb",
      "9566d93114e044209e9ebc1a4a46689b",
      "98208caa3a404583a455f374c611e563",
      "fe7c19a63dbc417abacedebcfe79b9fa",
      "cf57fbb19f264b85b8e8438bbd637e67",
      "7fa952b85ae541c5b7499a09dcaa0e42",
      "2e57a807d30348eb92f1bd6562236b5c",
      "7db8825f17ef477db287e05e541e8af5",
      "628bb28306bf40acb53269b6688b04be",
      "c8f093e66bad4e70aabbeb0badab92f0",
      "32fe83d1c8084e7d822c7e3addae8506",
      "98f8d1e24eee4a7982edc262d1e4de39",
      "405b044d917943f89884bd5a7abc42bd",
      "f055bad6455b445c803f4ab6289d96dd",
      "15cfddb6eb6e4c939cc0a73acad84d00",
      "2929dc98da924259bc82b45ff55a726f",
      "61bc6d8307664d20b49e1a35784b05a9",
      "8fd00a96bc224b67b2bda42910578ad0",
      "87dd3f5af22848ee886d8cc253a54c96",
      "9342e80251f4454fa693e7d30b1d44ba",
      "b2b711a1cc7c4fa3bca06a8c346629cb",
      "9ac10b56ac264a5b8a70d1c75909a46d",
      "973487a739234a058c22a03e5232fad1",
      "855329a01e25464a8b7aa48763b1db27",
      "1a8f739d66b143ce8965dd363c0e4eb0",
      "74fdbed33d214937b2130e5d09167065",
      "528cc272f89e4875b9461b2f97dba6d4",
      "8cbd9861f79543f6a10f422f142986af",
      "145a605932d0469caf186365a34fc28a",
      "c19d112c0daf480a98694fa6ae9d1609",
      "ff0d39dc2f3d4329af3bc3f1a36eb7bc",
      "b2cb00cb5f9d4db2b4cb1a5ab039b525",
      "e880431e37fa4083952b3c41aaf2521a",
      "7ea373ce3f25480fb60020e8690b2c63",
      "381b2243a82b4ee98cc03a71340f48e5",
      "cb34cad1defb4009988d26dbb0d3c929",
      "31a7a11f2fcc4cbda997ae58c8ef8a10",
      "e38ff4e9efb34c9987faf33af24c581a",
      "427f077e055a49d18ef1065846aa201c",
      "87e99f847340494896737428dfcea06a",
      "dac91a2d8dc743c28fc1f32895883297",
      "436b1c68fc534703bf42ce57d63207e9",
      "95994be661bd44fa863c0b795e1e6dcd",
      "e27e11af42414ab292a415a2e9cdbd02",
      "0436c67195964b169b18d873087e2dd0",
      "e0dfddb8f5ae4b698e1f49a1404cc8bc",
      "f7677aded9504eb6af06e32d03c78238",
      "b35d3da05f244f29857a9eec159061eb",
      "d5635c0fb3004b6d838d2d19be071171",
      "2425ab92d95947c1b3cd86b30bec090f",
      "c3e0bc0b05524375b7860ad4980d5ed1",
      "ad063e7d111043a6a85e7a73a8cd53a5",
      "4f9f1307774d472cbe7c507dce980fe1",
      "e8301e8a3e154c878810e1fd11fb79cd",
      "2bb1e593d9374c4b94d6ee490fc9d080",
      "a9e5cd1efa854d949ba7b94b6c4d9393",
      "cbcf3f79a4fe4d5fa1782a9d4535b933",
      "8971fb61709843f89d08cc171f6d1aff",
      "e50b06e57c9342da936ff4cb2d3dc8e0",
      "9bea6e9a1e8e4b3d8bd141c7e0051614",
      "9e6c8d8b57fc4dac93ed9004a6eeb554",
      "af033c205bfa40a6bdddb2bc9f57cb4a",
      "1a35f53eaf0c40f093b0988d90051679",
      "05abc70240354bbb9c6b9e20ad312be6",
      "736238bdbdf14f6aa2c2f4a4f77270f0",
      "e89b71a4e0954f0286c49e36411510f1",
      "050565d1bdaa453da91a65bd79112dfe",
      "652eba7e49c64b0ea72e04a7a5ad9373",
      "a6ae1882361b4fc0bc640029d3438d2a",
      "d273cfa6af234301b03f5bdfbb297346",
      "f9bc0a79a8214c4e97138dcc9357600c",
      "097144df8b4c4fbda776ad69152bee71",
      "5ca6d4a1b4fe4505960232f6bf223f20",
      "84a0eedecaf741cbad8a6de656c940aa",
      "b15aabfeec3d43c0bee77471a48c9ad5",
      "8eb281dacfd5496bb67b022d29d58beb",
      "bfe94adcb0624c15935271d6aaa4b6c2",
      "2fb766ff85cd4bda9b3f98e4372e9805",
      "578e91d7398a45a8b46470de1f44280b",
      "f8c7c63f33cd4c2596487ddc193ffbd2",
      "402b72d3278b41b7a051f3599e4cd205",
      "3afd6d6807864ca69027a01585320db7",
      "609f60479fbe4e9d8d845e5ec90b9557",
      "22e5ca68f1c043fda89dc4007b0c8eee",
      "d4927661d4a040d4a684b37ed4f8a30f",
      "d204fce808304aafa59caf37b3ea26b1",
      "30d0d7aa4bea4d65be0648029822fc0d",
      "ab842a5e311349e188cad1ca39daa11d",
      "2b3fa278c46042a885597b9982f32751",
      "056dcafa3cc34cdca97dddf37370a362",
      "1073ad2282b84d99bb2ff3eeafa8bf90",
      "a5e439bb5d4a44f888b9b601cb1bcae0",
      "abd7007fb0c04e5ba133908a846f28cd",
      "fbc3e1f599d14337830e969e29c8c0db",
      "bb0f6a8870f64fd0af6f7093427ffb1a",
      "603e82c9fec647a79993cf8c213be26c",
      "dee07acd34584a4ea7a574c96a648d4e",
      "93f97bc5f672497c8984c9070d96afc6",
      "b56bf6e8bf35484581f7aaa2205cf51e",
      "888bce3b9a7343a18ef093c83cf08608",
      "8e18e2fda8444932953ffc293eaeeb27",
      "08467d0d31394f02848563c5ae174d70",
      "6555a78369174e9e8af2ebdf93b861e1",
      "3b1aac93e1df4368996cb4fd7022c6f1",
      "b13024c8dc164c9fb75275f44d70272e",
      "2006854ab82b4370a444888d3745141c",
      "ef9390eed1cf466fa38a16bc5347a372",
      "90c772ed687d4a1d9d0314b7e1434ad8",
      "663b816387444a20a0a79b8ed5115de2",
      "169426a44b7448288e9644131e06a6a4",
      "2c72d7be78f7417f842686fb25da1171",
      "c3df0278ff6a43b78f75e0a807977cd3",
      "45b5c56a31e941f48d07f3b4e30587f8",
      "a7b7e85502af4b0b873d4bd7cd58d8d3",
      "d94a61cbf4f64dce9ead3f0771654c7a",
      "a11302792aa04ab7882de5a71510f941",
      "9c0a84a163f046c1b9dd6ce485c18d99",
      "5f31f87d9fd04ad789e3d81e580cb6ae",
      "40b4282ddd414354aeb5747f9ddc08c9",
      "0b3f10d6fead41939a7cc42e976988f7",
      "a401e4a78ad541cb8e0f04df0374e83e",
      "d6bedcc14c6a4c698de9c779a349ea8d",
      "52e86ceed5e740e9a25ef2c31d1f6f22",
      "358c3c9e164f4545bbe83df1a155e621",
      "8db2498ee0cc4bd19945ff36c27da1bb",
      "67b5bb1ae17c404b96558772e696f986",
      "7cb06c87e465460cb61fcb9c7fbaf293",
      "4ff905358ab24832b69399111ac24c47",
      "d932312463df4de18e9ff3c470a36e14",
      "fb47efc8078e46969f91a6a32c821059",
      "3719e2a0d33340e692e377e2ba7f9846",
      "3086463987494517bf1a6010c2e4efb7"
     ]
    },
    "collapsed": true,
    "id": "3x3BMGzNLb5y",
    "outputId": "f0e51278-91ee-4aac-c4ce-05580887de3d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e8583863f2843888fccac84beaa6bbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82bc6fe3109146879c43aeb0a8227f26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/3.11M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4004c1b3b82249bd8bd36d4f00bc40cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation-00000-of-00001.parquet:   0%|          | 0.00/72.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98f8d1e24eee4a7982edc262d1e4de39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test-00000-of-00001.parquet:   0%|          | 0.00/148k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "973487a739234a058c22a03e5232fad1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/67349 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ea373ce3f25480fb60020e8690b2c63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/872 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0436c67195964b169b18d873087e2dd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/1821 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9e5cd1efa854d949ba7b94b6c4d9393",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "050565d1bdaa453da91a65bd79112dfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fb766ff85cd4bda9b3f98e4372e9805",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b3fa278c46042a885597b9982f32751",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "888bce3b9a7343a18ef093c83cf08608",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/67349 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c72d7be78f7417f842686fb25da1171",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/872 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6bedcc14c6a4c698de9c779a349ea8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1821 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load SST-2 (Stanford Sentiment Treebank)\n",
    "dataset = load_dataset(\"glue\", \"sst2\")\n",
    "\n",
    "# Use pretrained tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Tokenize function\n",
    "def tokenize_fn(example):\n",
    "    return tokenizer(\n",
    "        example[\"sentence\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=128,\n",
    "    )\n",
    "\n",
    "# Apply tokenization\n",
    "tokenized = dataset.map(tokenize_fn, batched=True)\n",
    "tokenized.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EAQWDNPfMSLd"
   },
   "source": [
    "# Train/Val Split & DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rG7W7dG7L_9E"
   },
   "outputs": [],
   "source": [
    "train_data = tokenized[\"train\"]\n",
    "val_data = tokenized[\"validation\"]\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=64)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a9ORQe_VMZbA"
   },
   "source": [
    "# Define LoRA Module & Inject into BERT Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KFcp9LryMUER"
   },
   "outputs": [],
   "source": [
    "class LoRALinear(nn.Module):\n",
    "    def __init__(self, original_linear: nn.Linear, r: int = 4, alpha: int = 16):\n",
    "        super().__init__()\n",
    "        self.in_features = original_linear.in_features\n",
    "        self.out_features = original_linear.out_features\n",
    "        self.r = r\n",
    "        self.alpha = alpha\n",
    "\n",
    "        # Original frozen weight\n",
    "        self.weight = original_linear.weight\n",
    "        self.bias = original_linear.bias\n",
    "\n",
    "        # LoRA adapters (A: down-projection, B: up-projection)\n",
    "        self.A = nn.Parameter(torch.randn(r, self.in_features) * 0.01)\n",
    "        self.B = nn.Parameter(torch.randn(self.out_features, r) * 0.01)\n",
    "\n",
    "        # Scaling factor\n",
    "        self.scaling = self.alpha / self.r\n",
    "\n",
    "        # Freeze the original weight\n",
    "        self.weight.requires_grad = False\n",
    "        if self.bias is not None:\n",
    "            self.bias.requires_grad = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        # LoRA: W(x) + alpha/r * BA(x)\n",
    "        lora_update = (x @ self.A.T) @ self.B.T\n",
    "        return nn.functional.linear(x, self.weight) + self.scaling * lora_update\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z9J1AbVhMeuV"
   },
   "source": [
    "# Inject LoRA into BERT Attention Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iLe3WMkJMhep"
   },
   "outputs": [],
   "source": [
    "def inject_lora_into_bert(model, r=4, alpha=16):\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, nn.Linear) and (\"attention.self.query\" in name or \"attention.self.value\" in name):\n",
    "            parent = get_parent_module(model, name)\n",
    "            layer_name = name.split(\".\")[-1]\n",
    "            setattr(parent, layer_name, LoRALinear(module, r=r, alpha=alpha))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4Pc9ABw7MjBk"
   },
   "outputs": [],
   "source": [
    "def get_parent_module(model, module_name):\n",
    "    components = module_name.split(\".\")\n",
    "    for comp in components[:-1]:\n",
    "        model = getattr(model, comp)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vz4q1iewMmw4"
   },
   "source": [
    "## Load Pretrained BERT & Inject LoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 864,
     "referenced_widgets": [
      "8e2586209e85414faac20ad0468e9ca1",
      "3be34fd8dd0947e18981f6f159821962",
      "adf05080c77f4de3b46d60f3a792657b",
      "e5a92450da8b48f6ba69f7eda0c523d0",
      "673278e28a90488e94ba9ef534f8d6d2",
      "095388977dc84015bdf1dc02d5011819",
      "26311c9c7f9e4eebadacd4adee50e03d",
      "15983fbd33934edd826bf2fbe0dffb0b",
      "185db927b91e410fa5909923e90da767",
      "0cfea58dd4494b09a3a86aeb39c74b66",
      "2fc9d44a01d3409f9957269734671d09"
     ]
    },
    "collapsed": true,
    "id": "xIyOb1k3Mkaf",
    "outputId": "317e342f-0d7a-4c40-ee4e-5ae6865af307"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e2586209e85414faac20ad0468e9ca1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): LoRALinear()\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): LoRALinear()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lora_config = {\"r\": 4, \"alpha\": 16}\n",
    "\n",
    "# Load BERT-base for binary classification\n",
    "model_lora = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
    "inject_lora_into_bert(model_lora, **lora_config)\n",
    "model_lora.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SxpAztxIMs5U"
   },
   "source": [
    "## Freeze All But LoRA Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HwxIcZt_MubE"
   },
   "outputs": [],
   "source": [
    "# Freeze all parameters\n",
    "for param in model_lora.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Enable training only for LoRA adapters\n",
    "for name, param in model_lora.named_parameters():\n",
    "    if \"A\" in name or \"B\" in name:\n",
    "        param.requires_grad = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VzoFCUt-M2Fn"
   },
   "source": [
    "# Train LoRA-injected BERT on SST-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qYUjKqFEM78c"
   },
   "outputs": [],
   "source": [
    "def train(model, dataloader, optimizer, criterion):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in tqdm(dataloader, desc=\"Training\", leave=False):\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"label\"].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        loss = criterion(logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v8PGX2bnM_jK"
   },
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader):\n",
    "    model.eval()\n",
    "    preds, labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels.extend(batch[\"label\"].cpu().numpy())\n",
    "\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "            pred = torch.argmax(logits, dim=-1).cpu().numpy()\n",
    "            preds.extend(pred)\n",
    "\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    report = classification_report(labels, preds, output_dict=True)\n",
    "    return acc, report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q3eJZb89M_3y",
    "outputId": "6db99749-e551-40bf-ba20-c10440764b1d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:   0%|          | 0/2105 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3326 | Validation Accuracy: 0.8991\n",
      "\n",
      "Epoch 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:   0%|          | 0/2105 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2424 | Validation Accuracy: 0.9094\n",
      "\n",
      "Epoch 3/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:   0%|          | 0/2105 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2150 | Validation Accuracy: 0.9174\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import AdamW\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "optimizer = AdamW(filter(lambda p: p.requires_grad, model_lora.parameters()), lr=1e-4)\n",
    "criterion = CrossEntropyLoss()\n",
    "\n",
    "epochs = 3\n",
    "for epoch in range(epochs):\n",
    "    print(f\"\\nEpoch {epoch + 1}/{epochs}\")\n",
    "    train_loss = train(model_lora, train_loader, optimizer, criterion)\n",
    "    val_acc, _ = evaluate(model_lora, val_loader)\n",
    "\n",
    "    print(f\"Train Loss: {train_loss:.4f} | Validation Accuracy: {val_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jVeCU7TBYc02"
   },
   "source": [
    "# Comparison â€” LoRA vs Full Fine-Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZzkQuK9CX24X",
    "outputId": "f93c7975-31ff-4cb5-dec5-10bfdff7f47e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LoRA Trainable Params: 147,456\n"
     ]
    }
   ],
   "source": [
    "def count_trainable(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "lora_params = count_trainable(model_lora)\n",
    "\n",
    "print(f\"LoRA Trainable Params: {lora_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x1UEWt2gYhxW",
    "outputId": "a2dd8c55-b850-4895-a1de-414d99df73f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š Final Accuracy:\n",
      "LoRA       : 0.9174\n"
     ]
    }
   ],
   "source": [
    "lora_acc, lora_report = evaluate(model_lora, val_loader)\n",
    "\n",
    "print(f\"\\nðŸ“Š Final Accuracy:\")\n",
    "print(f\"LoRA       : {lora_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "veZFk--JYjgI",
    "outputId": "dbdf6d87-1ef4-40f0-d2f0-8852e2c32e1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ§¾ LoRA Classification Report:\n",
      "{'0': {'precision': 0.8973214285714286, 'recall': 0.9392523364485982, 'f1-score': 0.9178082191780822, 'support': 428.0}, '1': {'precision': 0.9386792452830188, 'recall': 0.8963963963963963, 'f1-score': 0.9170506912442397, 'support': 444.0}, 'accuracy': 0.9174311926605505, 'macro avg': {'precision': 0.9180003369272237, 'recall': 0.9178243664224972, 'f1-score': 0.9174294552111609, 'support': 872.0}, 'weighted avg': {'precision': 0.9183797664383393, 'recall': 0.9174311926605505, 'f1-score': 0.9174225054136027, 'support': 872.0}}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(\"\\nðŸ§¾ LoRA Classification Report:\")\n",
    "print(lora_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cin0_DwQYnDr"
   },
   "source": [
    "# Inference on Real Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "Aap6L3ueYo7Y"
   },
   "outputs": [],
   "source": [
    "def predict_sentiment(text, model, tokenizer):\n",
    "    model.eval()\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=128).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "        probs = torch.softmax(logits, dim=-1)\n",
    "        pred = torch.argmax(probs, dim=-1).item()\n",
    "        confidence = probs[0, pred].item()\n",
    "\n",
    "    label = \"Positive\" if pred == 1 else \"Negative\"\n",
    "    return label, confidence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MOcXeEQIYq5c",
    "outputId": "e667cff6-39eb-4be8-9a06-e878544948ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§  Inference Results\n",
      "\n",
      "ðŸ”¹ Sentence: The movie was fantastic and thrilling!\n",
      "   LoRA âž¤ Positive (0.98)\n",
      "ðŸ”¹ Sentence: I wouldn't recommend it to anyone.\n",
      "   LoRA âž¤ Negative (0.90)\n",
      "ðŸ”¹ Sentence: It was okay, not great but not bad.\n",
      "   LoRA âž¤ Positive (0.93)\n",
      "ðŸ”¹ Sentence: This is one of the best performances I've seen.\n",
      "   LoRA âž¤ Positive (0.98)\n",
      "ðŸ”¹ Sentence: The film lacked a solid storyline.\n",
      "   LoRA âž¤ Negative (0.98)\n"
     ]
    }
   ],
   "source": [
    "sentences = [\n",
    "    \"The movie was fantastic and thrilling!\",\n",
    "    \"I wouldn't recommend it to anyone.\",\n",
    "    \"It was okay, not great but not bad.\",\n",
    "    \"This is one of the best performances I've seen.\",\n",
    "    \"The film lacked a solid storyline.\",\n",
    "]\n",
    "\n",
    "print(\"ðŸ§  Inference Results\\n\")\n",
    "for text in sentences:\n",
    "    lora_label, lora_conf = predict_sentiment(text, model_lora, tokenizer)\n",
    "\n",
    "    print(f\"ðŸ”¹ Sentence: {text}\")\n",
    "    print(f\"   LoRA âž¤ {lora_label} ({lora_conf:.2f})\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
